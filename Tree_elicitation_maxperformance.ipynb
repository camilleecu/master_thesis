{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8284ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1271f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in /Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/thesis_github/lib/python3.9/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/thesis_github/lib/python3.9/site-packages (from surprise) (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/thesis_github/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/thesis_github/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/thesis_github/lib/python3.9/site-packages (from scikit-surprise->surprise) (1.13.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import pysparnn.cluster_index as ci\n",
    "# import scipy.sparse\n",
    "# import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from re_sample.utils import train_test_split, df_to_matrix ,matrix_to_df_2, threshold_interactions_df, matrix_to_df,set_intersection,get_0_and_p_index,set_diff, matrix_to_full_df\n",
    "\n",
    "!pip install surprise\n",
    "from surprise import Reader, accuracy\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pct.tree.heuristic.Heuristic import Heuristic5\n",
    "from pct.tree.heuristic.NumericHeuristic_movie import NumericHeuristic5\n",
    "from pct.tree.splitter.splitter import Splitter\n",
    "from pct.tree.tree_movie import Tree\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f26573-f986-4205-9b9d-dd8041ae788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactions info\n",
      "Number of rows: 6040\n",
      "Number of cols: 3706\n",
      "Sparsity: 4.468%\n",
      "Ending interactions info\n",
      "Number of rows: 2828\n",
      "Number of columns: 1919\n",
      "Sparsity: 14.284%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/ml-1m/ratings.txt\",sep='::',index_col=False,names=[\"user_id\",\"item_id\",\"rating\",\"timestamp\"],header=None,engine='python')\n",
    "my_seed = 7\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "# Iteratively filters out users and items with fewer than the threshold number of interactions until no changes happen.\n",
    "data = threshold_interactions_df(data,'user_id','item_id',100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2a475",
   "metadata": {},
   "source": [
    "# only cold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f89b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting interactions info\n",
      "Number of rows: 6040\n",
      "Number of cols: 3706\n",
      "Sparsity: 4.468%\n",
      "Ending interactions info\n",
      "Number of rows: 2828\n",
      "Number of columns: 1919\n",
      "Sparsity: 14.284%\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/ml-1m/ratings.txt\",sep='::',index_col=False,names=[\"user_id\",\"item_id\",\"rating\",\"timestamp\"],header=None,engine='python')\n",
    "my_seed = 7\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "# Iteratively filters out users and items with fewer than the threshold number of interactions until no changes happen.\n",
    "data = threshold_interactions_df(data,'user_id','item_id',100,100)\n",
    "matrix,rid_to_idx, idx_to_rid, cid_to_idx, idx_to_cid = df_to_matrix(data,\"user_id\",\"item_id\",\"rating\")\n",
    "\n",
    "# split to train, X and eval sets\n",
    "al,train,_ = train_test_split(matrix,1) # train_test_split(interactions, split_count, fraction=None)\n",
    "# train: a matrix containing only the 1 held-out rating per user\n",
    "\n",
    "# ml 1M\n",
    "X_matrix,test,_ = train_test_split(al,30)\n",
    "# test: a matrix containing only the 30 held-out ratings per user\n",
    "# X: a matrix containing the rest of the ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elicitation_by_tree_max_performance(\n",
    "    \n",
    "    train,              # lil_matrix: cold users' known ratings (1 item/user, updated over rounds)\n",
    "    test,               # lil_matrix: cold users' test ratings (30 ratings/user), fixed\n",
    "    X,                  # lil_matrix: cold users' \"hidden\" ratings, revealed 1 per round\n",
    "    idx_to_rid,    # cold user index → user_id\n",
    "    idx_to_cid,         # item index → item_id\n",
    "    # iteration=5\n",
    "):\n",
    "  \n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    # train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # KX is the matrix of cold train and cold X\n",
    "    KX = train.copy() + X.copy()\n",
    "    KX_df = matrix_to_df_2(KX, idx_to_rid, idx_to_cid) # Use combined mapping for KX_df\n",
    "\n",
    "    rmse_list, mae_list = [], []\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "\n",
    "    # Step 0: Baseline SVD using only cold-start (1 rating per user)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    algo = SVD()\n",
    "    KXtrainset = Dataset.load_from_df(KX_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset()\n",
    "    algo.fit(KXtrainset)\n",
    "\n",
    "    test_df = matrix_to_df_2(test, idx_to_rid, idx_to_cid)\n",
    "    testset = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"✅ Baseline evaluation complete.\")\n",
    "\n",
    "    \n",
    "\n",
    "     # Step 1: Prepare tree training data (warm + updated cold)\n",
    "    # warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "    # cold_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    # x_df = pd.concat([warm_df, cold_df], ignore_index=False)\n",
    "\n",
    "    # tree_model = tree_model_class(max_depth=i+1, min_instances=5)\n",
    "    # tree_model.fit(x_df, x_df)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    return rmse_list, mae_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34d08c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8575\n",
      "MAE:  0.6713\n",
      "✅ Baseline evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "max_performance_cold =elicitation_by_tree_max_performance(\n",
    "\n",
    "    train=train,\n",
    "    test=test,\n",
    "    X=X_matrix,\n",
    "    idx_to_rid =idx_to_rid,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    # iteration=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ccc75",
   "metadata": {},
   "source": [
    "## warm cold split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8633da-68ef-45f5-bed2-d5ec96424d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = sorted(data['user_id'].unique())\n",
    "warm_users = all_user_ids[:1414]\n",
    "cold_users = all_user_ids[1414:]\n",
    "\n",
    "\n",
    "df_warm = data[data['user_id'].isin(warm_users)].copy()\n",
    "df_cold = data[data['user_id'].isin(cold_users)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b6047d-3589-4065-aaf6-29cfb3056658",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_warm, rid_to_idx_warm, idx_to_rid_warm, cid_to_idx, idx_to_cid = df_to_matrix(\n",
    "    df_warm, \"user_id\", \"item_id\", \"rating\"\n",
    ")\n",
    "\n",
    "\n",
    "matrix_cold, rid_to_idx_cold, idx_to_rid_cold, _, _ = df_to_matrix(\n",
    "    df_cold, \"user_id\", \"item_id\", \"rating\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5308e8ea-fd5a-4da6-96d2-05c39c8c4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "al, train_cold_K, _ = train_test_split(matrix_cold, 1)\n",
    "\n",
    "\n",
    "X_cold, test_cold, _ = train_test_split(al, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddeb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create combined user index mapping\n",
    "combined_idx_to_rid = {\n",
    "    **idx_to_rid_warm,  # Original warm user indices\n",
    "    **{k + len(idx_to_rid_warm): v for k, v in idx_to_rid_cold.items()}  # Offset cold user indices\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff9084",
   "metadata": {},
   "source": [
    "#### KX = matrix_warm.copy() + train.copy() + X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eff8515-2820-46b5-9e6a-8c7c1ed52be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elicitation_by_tree_warm_max_performance(\n",
    "    \n",
    "    train,              # lil_matrix: cold users' known ratings (1 item/user, updated over rounds)\n",
    "    test,               # lil_matrix: cold users' test ratings (30 ratings/user), fixed\n",
    "    X,                  # lil_matrix: cold users' \"hidden\" ratings, revealed 1 per round\n",
    "    matrix_warm,        # lil_matrix: warm users' full ratings\n",
    "    idx_to_rid_cold,    # cold user index → user_id\n",
    "    idx_to_rid_warm,    # warm user index → user_id\n",
    "    idx_to_cid,         # item index → item_id\n",
    "    iteration=5\n",
    "):\n",
    "\n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    # train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # KX is the matrix of warm, cold train and cold X\n",
    "    cold_KX = train.copy() + X.copy()\n",
    "    warm_coldKX = sp.vstack([matrix_warm.copy(), cold_KX.copy()])\n",
    "    warm_coldKX_copy = warm_coldKX.tolil().copy()\n",
    "    KX_df = matrix_to_df_2(warm_coldKX_copy, combined_idx_to_rid, idx_to_cid) # Use combined mapping for KX_df\n",
    "\n",
    "    rmse_list, mae_list = [], []\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "\n",
    "    # Step 0: Baseline SVD using only cold-start (1 rating per user)\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    algo = SVD()\n",
    "    KXtrainset = Dataset.load_from_df(KX_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset()\n",
    "    algo.fit(KXtrainset)\n",
    "\n",
    "    test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "    testset = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"✅ Baseline evaluation complete.\")\n",
    "\n",
    "    \n",
    "\n",
    "     # Step 1: Prepare tree training data (warm + updated cold)\n",
    "    # warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "    # cold_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    # x_df = pd.concat([warm_df, cold_df], ignore_index=False)\n",
    "\n",
    "    # tree_model = tree_model_class(max_depth=i+1, min_instances=5)\n",
    "    # tree_model.fit(x_df, x_df)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    return rmse_list, mae_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c968b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8783\n",
      "MAE:  0.6876\n",
      "✅ Baseline evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "max_performance =elicitation_by_tree_warm_max_performance(\n",
    "\n",
    "    train=train_cold_K,\n",
    "    test=test_cold,\n",
    "    X=X_cold,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    # iteration=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f52eff-60cc-4556-948a-f5bdebf78601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5e609f0",
   "metadata": {},
   "source": [
    "# max performance : Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pct.tree.heuristic.NumericHeuristic_yahoo import NumericHeuristic5\n",
    "from pct.tree.tree_yahoo import Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa1e40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv('/Users/camillecu/Downloads/KUL/master_thesis/master_thesis_github/re_sample/filtered_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42804ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = sorted(filtered_df['user_id'].unique())\n",
    "\n",
    "def split_users_by_ratio(all_user_ids, ratio):\n",
    "    n = len(all_user_ids)\n",
    "    split_point = int(n * ratio)\n",
    "    warm_users = all_user_ids[:split_point]\n",
    "    cold_users = all_user_ids[split_point:]\n",
    "    return warm_users, cold_users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76307574",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_users_idx, cold_users_idx = split_users_by_ratio(all_user_ids, 0.1)\n",
    "\n",
    "df_warm = filtered_df[filtered_df['user_id'].isin(warm_users_idx)].copy()\n",
    "df_cold = filtered_df[filtered_df['user_id'].isin(cold_users_idx)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f826f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_warm, rid_to_idx_warm, idx_to_rid_warm, cid_to_idx, idx_to_cid = df_to_matrix(\n",
    "    df_warm, \"user_id\", \"item_id\", \"rating\"\n",
    ")\n",
    "\n",
    "\n",
    "matrix_cold, rid_to_idx_cold, idx_to_rid_cold, _, _ = df_to_matrix(\n",
    "    df_cold, \"user_id\", \"item_id\", \"rating\"\n",
    ")\n",
    "\n",
    "al, train_cold_K, _ = train_test_split(matrix_cold, 1)\n",
    "\n",
    "\n",
    "X_cold, test_cold, _ = train_test_split(al, 30)\n",
    "\n",
    "\n",
    "# Create combined user index mapping\n",
    "combined_idx_to_rid = {\n",
    "    **idx_to_rid_warm,  # Original warm user indices\n",
    "    **{k + len(idx_to_rid_warm): v for k, v in idx_to_rid_cold.items()}  # Offset cold user indices\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elicitation_by_tree_max_performance_yahoo(\n",
    "    \n",
    "    train,              # lil_matrix: cold users' known ratings (1 item/user, updated over rounds)\n",
    "    test,               # lil_matrix: cold users' test ratings (30 ratings/user), fixed\n",
    "    X,                  # lil_matrix: cold users' \"hidden\" ratings, revealed 1 per round\n",
    "    # matrix_warm,        # lil_matrix: warm users' full ratings\n",
    "    idx_to_rid_cold,    # cold user index → user_id\n",
    "    # idx_to_rid_warm,    # warm user index → user_id\n",
    "    idx_to_cid,         # item index → item_id\n",
    "    iteration=5\n",
    "):\n",
    "\n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    # train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # KX is the matrix of warm, cold train and cold X\n",
    "    cold_KX = train.copy() + X.copy()\n",
    "    # warm_coldKX = sp.vstack([matrix_warm.copy(), cold_KX.copy()])\n",
    "    # warm_coldKX_copy = warm_coldKX.tolil().copy()\n",
    "    KX_df = matrix_to_df_2(cold_KX, idx_to_rid_cold, idx_to_cid) # Use combined mapping for KX_df\n",
    "\n",
    "    rmse_list, mae_list = [], []\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "\n",
    "    # Step 0: Baseline SVD using only cold-start (1 rating per user)\n",
    "    reader = Reader(rating_scale=(1, 100))\n",
    "    algo = SVD()\n",
    "    KXtrainset = Dataset.load_from_df(KX_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset()\n",
    "    algo.fit(KXtrainset)\n",
    "\n",
    "    test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "    testset = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"✅ Baseline evaluation complete.\")\n",
    "\n",
    "    \n",
    "\n",
    "     # Step 1: Prepare tree training data (warm + updated cold)\n",
    "    # warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "    # cold_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    # x_df = pd.concat([warm_df, cold_df], ignore_index=False)\n",
    "\n",
    "    # tree_model = tree_model_class(max_depth=i+1, min_instances=5)\n",
    "    # tree_model.fit(x_df, x_df)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    return rmse_list, mae_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3cba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 52.4292\n",
      "MAE:  45.0758\n",
      "✅ Baseline evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "max_performance_yahoo =elicitation_by_tree_max_performance_yahoo(\n",
    "\n",
    "    train=train_cold_K,\n",
    "    test=test_cold,\n",
    "    X=X_cold,\n",
    "    # matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    # idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    # iteration=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f10e4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elicitation_by_tree_warm_max_performance_yahoo(\n",
    "    \n",
    "    train,              # lil_matrix: cold users' known ratings (1 item/user, updated over rounds)\n",
    "    test,               # lil_matrix: cold users' test ratings (30 ratings/user), fixed\n",
    "    X,                  # lil_matrix: cold users' \"hidden\" ratings, revealed 1 per round\n",
    "    matrix_warm,        # lil_matrix: warm users' full ratings\n",
    "    idx_to_rid_cold,    # cold user index → user_id\n",
    "    idx_to_rid_warm,    # warm user index → user_id\n",
    "    idx_to_cid,         # item index → item_id\n",
    "    iteration=5\n",
    "):\n",
    "\n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    # train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # KX is the matrix of warm, cold train and cold X\n",
    "    cold_KX = train.copy() + X.copy()\n",
    "    warm_coldKX = sp.vstack([matrix_warm.copy(), cold_KX.copy()])\n",
    "    warm_coldKX_copy = warm_coldKX.tolil().copy()\n",
    "    KX_df = matrix_to_df_2(warm_coldKX_copy, combined_idx_to_rid, idx_to_cid) # Use combined mapping for KX_df\n",
    "\n",
    "    rmse_list, mae_list = [], []\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "\n",
    "    # Step 0: Baseline SVD using only cold-start (1 rating per user)\n",
    "    reader = Reader(rating_scale=(1, 100))\n",
    "    algo = SVD()\n",
    "    KXtrainset = Dataset.load_from_df(KX_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset()\n",
    "    algo.fit(KXtrainset)\n",
    "\n",
    "    test_df = matrix_to_df_2(test, combined_idx_to_rid, idx_to_cid)\n",
    "    testset = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader).build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"✅ Baseline evaluation complete.\")\n",
    "\n",
    "    \n",
    "\n",
    "     # Step 1: Prepare tree training data (warm + updated cold)\n",
    "    # warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "    # cold_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    # x_df = pd.concat([warm_df, cold_df], ignore_index=False)\n",
    "\n",
    "    # tree_model = tree_model_class(max_depth=i+1, min_instances=5)\n",
    "    # tree_model.fit(x_df, x_df)\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    return rmse_list, mae_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a885e000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 52.4292\n",
      "MAE:  45.0758\n",
      "✅ Baseline evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "max_performance_yahoo =elicitation_by_tree_warm_max_performance_yahoo(\n",
    "\n",
    "    train=train_cold_K,\n",
    "    test=test_cold,\n",
    "    X=X_cold,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    # iteration=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f065654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "935b0fa0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10b751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
