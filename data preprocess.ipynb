{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbaf42b3-1fbe-4337-98e4-2a8c16049305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the u.data dataset\n",
    "u_data = pd.read_csv('C:/Users/13447/Desktop/Stats thesis/ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Perform label encoding on user_id and item_id\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "u_data['user_id'] = user_encoder.fit_transform(u_data['user_id'])\n",
    "u_data['item_id'] = item_encoder.fit_transform(u_data['item_id'])\n",
    "\n",
    "# Create the rating matrix\n",
    "n_users = u_data['user_id'].nunique()\n",
    "n_items = u_data['item_id'].nunique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac192fad-a7d0-488c-9fab-6b32cf4b50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Training Rating Matrix:\n",
      "item_id  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
      "user_id                                                              ...   \n",
      "0         0.0   3.0   4.0   0.0   3.0   0.0   4.0   0.0   5.0   3.0  ...   \n",
      "1         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "4         4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "item_id  1667  1669  1670  1671  1672  1675  1677  1678  1679  1680  \n",
      "user_id                                                              \n",
      "0         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 1653 columns]\n",
      "\n",
      "Thresholded Training Rating Matrix:\n",
      "item_id  0     1     2     3     4     5     6     7     8     9     ...  \\\n",
      "user_id                                                              ...   \n",
      "0           0    -1     1     0    -1     0     1     0     1    -1  ...   \n",
      "1           1     0     0     0     0     0     0     0     0     0  ...   \n",
      "2           0     0     0     0     0     0     0     0     0     0  ...   \n",
      "3           0     0     0     0     0     0     0     0     0     0  ...   \n",
      "4           1     0     0     0     0     0     0     0     0     0  ...   \n",
      "\n",
      "item_id  1667  1669  1670  1671  1672  1675  1677  1678  1679  1680  \n",
      "user_id                                                              \n",
      "0           0     0     0     0     0     0     0     0     0     0  \n",
      "1           0     0     0     0     0     0     0     0     0     0  \n",
      "2           0     0     0     0     0     0     0     0     0     0  \n",
      "3           0     0     0     0     0     0     0     0     0     0  \n",
      "4           0     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 1653 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the threshold\n",
    "THRESHOLD = 3  # Ratings above this are \"Lovers\", below are \"Haters\"\n",
    "\n",
    "# Create a user-item matrix with users as rows and items as columns, and fill missing values with 0\n",
    "rating_matrix = u_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "\n",
    "# Keep a copy of the original rating matrix (before thresholding)\n",
    "original_rating_matrix = rating_matrix.copy()\n",
    "\n",
    "# Apply threshold classification to the rating matrix (after thresholding)\n",
    "rating_matrix_thresholded = rating_matrix.apply(lambda x: x.map(lambda y: 1 if y > THRESHOLD else (-1 if y > 0 else 0)))\n",
    "\n",
    "# Split the data into training (R) and testing (T) sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(u_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the rating matrix for training data (R) and fill missing values with 0\n",
    "rating_matrix_train = train_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "\n",
    "# Keep a copy of the original training rating matrix\n",
    "original_rating_matrix_train = rating_matrix_train.copy()\n",
    "\n",
    "# Apply threshold classification to the training rating matrix (after thresholding)\n",
    "rating_matrix_train_thresholded = rating_matrix_train.apply(lambda x: x.map(lambda y: 1 if y > THRESHOLD else (-1 if y > 0 else 0)))\n",
    "\n",
    "# Create the rating matrix for testing data (T) and fill missing values with 0\n",
    "rating_matrix_test = test_data.pivot(index='user_id', columns='item_id', values='rating').fillna(0)\n",
    "\n",
    "# Keep a copy of the original testing rating matrix\n",
    "original_rating_matrix_test = rating_matrix_test.copy()\n",
    "\n",
    "# Apply threshold classification to the testing rating matrix (after thresholding)\n",
    "rating_matrix_test_thresholded = rating_matrix_test.apply(lambda x: x.map(lambda y: 1 if y > THRESHOLD else (-1 if y > 0 else 0)))\n",
    "\n",
    "# Display the first few rows of the original and thresholded training rating matrices\n",
    "print(\"Original Training Rating Matrix:\")\n",
    "print(original_rating_matrix_train.head())\n",
    "\n",
    "print(\"\\nThresholded Training Rating Matrix:\")\n",
    "print(rating_matrix_train_thresholded.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35320cb7-e08a-4e59-b19b-6de82eb9e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rI and rU indexes for training set (R)\n",
    "# rI: item to user ratings (dictionary of items with lists of user ratings)\n",
    "rI_train = {}\n",
    "for _, row in train_data.iterrows():\n",
    "    item_id = row['item_id']\n",
    "    user_id = row['user_id']\n",
    "    rating = row['rating']\n",
    "    if item_id not in rI_train:\n",
    "        rI_train[item_id] = []\n",
    "    rI_train[item_id].append((user_id, rating))\n",
    "\n",
    "# rU: user to item ratings (dictionary of users with lists of item ratings)\n",
    "rU_train = {}\n",
    "for _, row in train_data.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    item_id = row['item_id']\n",
    "    rating = row['rating']\n",
    "    if user_id not in rU_train:\n",
    "        rU_train[user_id] = []\n",
    "    rU_train[user_id].append((item_id, rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920351d0-75fa-48eb-821d-44e1866d4c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample rI (item to user ratings) for Training Set:\n",
      "Item 1410: [(806, 1), (324, 4), (659, 2), (193, 1), (933, 4), (384, 3), (245, 2), (931, 4), (845, 4), (842, 3), (268, 3), (307, 4), (621, 4), (726, 2), (304, 3), (797, 1), (434, 1), (199, 3), (587, 1), (278, 3), (270, 2), (880, 2), (803, 3), (306, 4), (302, 2)]\n",
      "Item 658: [(473, 5), (773, 3), (920, 5), (12, 3), (658, 3), (804, 3), (814, 5), (415, 5), (124, 4), (84, 4), (58, 3), (17, 4), (869, 4), (715, 4), (369, 4), (748, 5), (642, 5), (526, 4), (282, 5), (312, 4), (693, 4), (235, 3), (263, 5), (296, 4), (502, 5), (217, 4), (835, 5), (406, 5), (888, 4), (386, 4), (513, 3), (765, 3), (697, 3), (325, 4), (882, 3), (408, 5), (567, 3), (495, 3), (252, 5), (392, 4), (238, 3), (320, 4), (891, 4), (451, 4), (378, 5), (434, 4), (59, 4), (425, 4), (766, 5), (795, 3), (384, 4), (797, 4), (400, 3), (449, 5), (353, 4), (638, 3), (193, 4), (566, 4), (397, 3), (917, 4), (453, 2), (941, 5), (911, 5), (663, 5), (652, 1), (540, 5), (931, 5), (737, 4), (839, 5), (326, 4), (910, 3), (291, 5), (311, 5), (520, 4), (547, 4), (10, 5), (89, 4), (669, 5), (157, 5), (360, 5), (622, 5), (6, 5), (532, 4), (390, 4), (150, 5), (877, 4), (278, 5), (295, 5)]\n",
      "\n",
      "Sample rU (user to item ratings) for Training Set:\n",
      "User 806: [(1410, 1), (101, 4), (180, 5), (384, 4), (623, 3), (1088, 4), (469, 5), (404, 4), (819, 3), (126, 3), (90, 5), (1443, 3), (1090, 3), (141, 3), (624, 3), (49, 5), (514, 4), (153, 2), (841, 4), (203, 4), (549, 5), (698, 4), (94, 4), (509, 5), (704, 4), (415, 3), (464, 4), (482, 5), (540, 4), (526, 5), (629, 4), (120, 4), (470, 4), (621, 3), (135, 5), (229, 4), (418, 5), (67, 4), (575, 4), (416, 3), (143, 4), (1412, 2), (420, 3), (484, 5), (78, 5), (251, 4), (205, 2), (226, 4), (403, 3), (98, 5), (490, 5), (379, 4), (1408, 4), (522, 3), (472, 3), (431, 5), (1137, 5), (545, 4), (583, 4), (738, 4), (299, 5), (81, 4), (385, 4), (604, 3), (678, 4), (88, 4), (419, 3), (142, 4), (595, 4), (70, 5), (842, 2), (541, 5), (257, 3), (434, 3), (372, 4), (72, 3), (1062, 4), (587, 5), (380, 2), (483, 4), (448, 5), (569, 4), (422, 5), (1033, 5), (233, 3), (494, 4), (95, 3), (210, 4), (207, 4), (626, 4), (140, 3), (945, 3), (256, 4), (1132, 3), (407, 3), (414, 3), (577, 4), (632, 4), (209, 4), (288, 4), (234, 1), (1075, 3), (312, 5), (192, 4), (656, 4), (527, 4), (172, 3), (635, 4), (68, 5), (176, 4), (383, 4), (194, 3), (61, 3), (193, 4), (228, 4), (317, 5), (997, 3), (221, 4), (1, 4), (553, 4), (1083, 4), (825, 3), (401, 5), (525, 5), (565, 4), (93, 2), (264, 5), (270, 3), (542, 2), (1482, 4), (1049, 5), (1038, 4), (1065, 5), (967, 4), (198, 5), (968, 4), (62, 5), (495, 5), (238, 4), (357, 3), (230, 4), (150, 4), (1015, 4), (134, 5), (27, 4), (132, 5), (742, 3), (373, 3), (427, 4), (139, 3), (171, 5), (297, 4), (398, 4), (596, 4), (1077, 4), (609, 3), (7, 4), (117, 4), (397, 3), (421, 4), (185, 4), (747, 4), (519, 5), (100, 4), (497, 4), (504, 3), (392, 4), (167, 4), (476, 4), (402, 4)]\n",
      "User 473: [(658, 5), (615, 4), (288, 3), (257, 4), (41, 4), (185, 4), (55, 5), (1015, 3), (290, 4), (256, 3), (1010, 4), (211, 4), (506, 4), (518, 4), (14, 5), (486, 4), (177, 4), (342, 3), (503, 5), (791, 4), (1122, 4), (136, 5), (647, 4), (60, 3), (44, 5), (1027, 1), (170, 4), (755, 1), (47, 4), (605, 3), (617, 4), (30, 4), (488, 4), (184, 5), (707, 4), (322, 2), (603, 4), (608, 4), (214, 5), (1049, 4), (63, 5), (728, 4), (614, 4), (1171, 4), (193, 5), (516, 4), (125, 4), (247, 4), (58, 3), (167, 3), (182, 5), (1019, 3), (526, 5), (514, 5), (197, 3), (10, 5), (600, 5), (847, 4), (12, 5), (72, 3), (426, 5), (675, 3), (65, 4), (106, 3), (734, 4), (507, 3), (788, 4), (212, 4), (648, 4), (415, 4), (274, 3), (462, 5), (627, 4), (226, 4), (95, 4), (70, 5), (485, 4), (301, 5), (54, 4), (944, 4), (923, 4), (98, 4), (494, 4), (187, 5), (217, 4), (491, 4), (489, 5), (435, 3), (470, 3), (126, 5), (524, 4), (142, 4), (281, 4), (314, 5), (743, 3), (202, 5), (519, 5), (97, 5), (194, 5), (312, 4), (652, 4), (654, 5), (293, 3), (186, 5), (962, 5), (469, 3), (273, 3), (1220, 4), (706, 5), (133, 4), (384, 4), (99, 5), (178, 5), (71, 3), (285, 5), (497, 4), (1285, 2), (429, 3), (409, 2), (140, 4), (502, 4), (512, 5), (236, 4), (1013, 3), (583, 5), (116, 4), (683, 4), (203, 4), (315, 5), (965, 4), (284, 5), (490, 4), (955, 4), (640, 4), (229, 3), (610, 4), (942, 4), (479, 5), (316, 4), (461, 4), (601, 3), (189, 3), (581, 5), (495, 4), (3, 5), (604, 3), (938, 4), (505, 5), (345, 5), (210, 5), (552, 2), (487, 3), (473, 5), (21, 4), (659, 5), (684, 3), (85, 4), (175, 5), (646, 4), (509, 4), (660, 4), (25, 4), (1123, 4), (420, 3), (254, 4), (433, 4), (613, 4), (82, 3), (696, 4), (43, 3), (656, 5), (134, 5), (492, 4), (287, 3), (209, 5), (704, 3), (460, 5), (195, 5), (483, 5), (496, 5), (632, 4), (120, 4), (150, 3), (418, 4), (520, 5), (641, 4), (466, 4), (645, 4), (417, 3), (131, 4), (321, 4), (49, 5), (22, 4), (650, 5), (169, 4), (548, 5), (474, 4), (237, 4), (377, 4), (76, 5), (670, 3), (480, 4), (522, 5), (922, 4), (484, 4), (379, 4), (413, 4), (258, 1), (1062, 5), (649, 4), (135, 4), (478, 5), (173, 5), (181, 5), (243, 4), (422, 5), (606, 4), (529, 5), (410, 2), (513, 4), (130, 4), (662, 4), (207, 3), (356, 5), (78, 5), (27, 4), (609, 3), (13, 5), (220, 4), (69, 4), (735, 3), (91, 4), (527, 5), (172, 5), (508, 5), (477, 4), (434, 5), (7, 5), (282, 3), (528, 5), (1420, 4), (468, 4), (447, 5), (204, 5), (504, 5), (123, 5), (970, 4), (115, 5), (192, 4), (517, 4), (736, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Optionally, print rI and rU to check the data structure for training and testing\n",
    "print(\"\\nSample rI (item to user ratings) for Training Set:\")\n",
    "for item in list(rI_train.keys())[:2]:  # Display sample item indices\n",
    "    print(f\"Item {item}: {rI_train[item]}\")\n",
    "\n",
    "print(\"\\nSample rU (user to item ratings) for Training Set:\")\n",
    "for user in list(rU_train.keys())[:2]:  # Display sample user indices\n",
    "    print(f\"User {user}: {rU_train[user]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092c176-8948-4e7c-a2eb-3460be067b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
