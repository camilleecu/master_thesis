{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c86d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))  \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "064955c7-6535-4302-a999-57c927b4874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pysparnn.cluster_index as ci\n",
    "# import scipy.sparse\n",
    "# import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from utils_elicitation import train_test_split, df_to_matrix ,matrix_to_df_2, threshold_interactions_df, matrix_to_df,set_intersection,get_0_and_p_index,set_diff, matrix_to_full_df, threshold_interactions_df_plus, train_test_split_csr\n",
    "\n",
    "# !pip install surprise\n",
    "from surprise import Reader, accuracy\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pct.tree.heuristic.Heuristic_pair import Heuristic5\n",
    "from pct.tree.heuristic.NumericHeuristic_pair import NumericHeuristic5\n",
    "from pct.tree.splitter.splitter_yahoo import Splitter\n",
    "from pct.tree.Yahootree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74b799-9042-4572-872f-587da73263e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv(\"../Yahoodata/filtered_semi_binary.csv\")\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cccb84-a9fa-4029-a5fd-a4abb6752eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item type map\n",
    "item_type_map = filtered_df.drop_duplicates(subset='item_id')[['item_id', 'item_type']]\n",
    "item_type_map = dict(zip(item_type_map['item_id'], item_type_map['item_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9faf9fac-677d-44ae-82f5-9144bdcf2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_type(item_id):\n",
    "    return item_type_map.get(item_id, 'unknown')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d735d-1037-4e02-889c-fbd9a9c23bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_item_type(172223))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1e96b-cf4a-4df9-8ea1-8c09a6740405",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_item_type(238709))  \n",
    "print(get_item_type(141799))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "574e2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = sorted(filtered_df['user_id'].unique().tolist())\n",
    "\n",
    "def split_users_by_ratio(all_user_ids, ratio):\n",
    "    n = len(all_user_ids)\n",
    "    split_point = int(n * ratio)\n",
    "    warm_users = all_user_ids[:split_point]\n",
    "    cold_users = all_user_ids[split_point:]\n",
    "    return warm_users, cold_users\n",
    "\n",
    "# Example ratios from 10% to 50%\n",
    "# ratios = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# splits = {r: split_users_by_ratio(all_user_ids, r) for r in ratios}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4056d4",
   "metadata": {},
   "source": [
    "## 10% warm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfd5f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_users_idx, cold_users_idx = split_users_by_ratio(all_user_ids, 0.1)\n",
    "\n",
    "df_warm = filtered_df[filtered_df['user_id'].isin(warm_users_idx)].copy()\n",
    "df_cold = filtered_df[filtered_df['user_id'].isin(cold_users_idx)].copy()\n",
    "\n",
    "matrix_warm, rid_to_idx_warm, idx_to_rid_warm, cid_to_idx, idx_to_cid = df_to_matrix(\n",
    "    df_warm, \"user_id\", \"item_id\", \"rating\")\n",
    "\n",
    "\n",
    "matrix_cold, rid_to_idx_cold, idx_to_rid_cold, _, _ = df_to_matrix( \n",
    "    df_cold, \"user_id\", \"item_id\", \"rating\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a9d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_combine(strategy=\"artist-only\"):\n",
    "    \"\"\"Handles both approaches with proper matrix alignment\"\"\"\n",
    "    # Get full cold matrix and mappings\n",
    "    matrix_cold, rid_to_idx_cold, _, cid_to_idx, _ = df_to_matrix(\n",
    "        df_cold, \"user_id\", \"item_id\", \"rating\"\n",
    "    )\n",
    "    matrix_cold = matrix_cold.tocsr()\n",
    "\n",
    "    # Create boolean masks\n",
    "    artist_mask = np.isin(\n",
    "        np.arange(matrix_cold.shape[1]), \n",
    "        [cid_to_idx[iid] for iid in df_cold[df_cold['item_type'] == 'artist']['item_id']]\n",
    "    )\n",
    "    genre_mask = ~artist_mask\n",
    "\n",
    "    # Create aligned matrices\n",
    "    matrix_cold_artist = matrix_cold.multiply(artist_mask)\n",
    "    matrix_cold_genre = matrix_cold.multiply(genre_mask)\n",
    "    matrix_cold_artist = matrix_cold.multiply(artist_mask).tocsr()\n",
    "    matrix_cold_genre = matrix_cold.multiply(genre_mask).tocsr()\n",
    "\n",
    "    al_artist, test_cold, _ = train_test_split(\n",
    "        matrix_cold_artist, \n",
    "        split_count=30,\n",
    "        fraction=None\n",
    "    )\n",
    "    \n",
    "    if strategy == \"artist-only\":\n",
    "        X_cold, K_cold, _ = train_test_split_csr(al_artist, 1)  \n",
    "        return K_cold, X_cold, test_cold\n",
    "    \n",
    "    elif strategy == \"hybrid\":\n",
    "        X_cold, K_cold, _ = train_test_split_csr(al_artist, 1)\n",
    "        X_cold = X_cold + matrix_cold_genre\n",
    "        return K_cold, X_cold, test_cold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96fa0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 7\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "train_cold_K_artist, X_cold_artist, test_cold_artist  = split_and_combine(\"artist-only\")\n",
    "train_cold_K_hybrid, X_cold_hybrid, test_cold_hybrid = split_and_combine(\"hybrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc19bf4-a23c-4b33-b45c-751ac90f83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cold users in X: {len(np.unique(X_cold_hybrid.nonzero()[0]))}\")\n",
    "print(f\"Cold items in X: {len(np.unique(X_cold_hybrid.nonzero()[1]))}\")\n",
    "print(f\"test users in test: {len(np.unique(test_cold_hybrid.nonzero()[0]))}\")\n",
    "print(f\"test items in test: {len(np.unique(test_cold_hybrid.nonzero()[1]))}\")\n",
    "print(f\"train users in train: {len(np.unique(train_cold_K_hybrid.nonzero()[0]))}\")\n",
    "print(f\"train items in train: {len(np.unique(train_cold_K_hybrid.nonzero()[1]))}\")\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "# shape of test_cold\n",
    "print(f\"Shape of test_cold: {test_cold_hybrid.shape}\")\n",
    "print(f\"Shape of train_cold: {train_cold_K_hybrid.shape}\")\n",
    "print(f\"Shape of X_cold: {X_cold_hybrid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f09c03-9cd8-4235-b86e-52375b580de4",
   "metadata": {},
   "source": [
    "# X with artist + genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "129c141a-2072-48bc-9696-1971546072be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elicitation_by_pairwise_tree_retrain_skiped(Tree, train, test, X, matrix_warm,\n",
    "                                                 idx_to_rid_cold, idx_to_rid_warm, idx_to_cid,\n",
    "                                                 iteration=5, strategy=1):\n",
    "    \"\"\"\n",
    "    Pairwise tree-based elicitation (skip asked pairs). Retrain tree each round.\n",
    "    At each iteration, select first unasked (itemA, itemB) pair and move both ratings from X to K.\n",
    "\n",
    "    Parameters:\n",
    "    - strategy: 1 (top2), 2 (most similar), 3 (least similar)\n",
    "\n",
    "    Returns:\n",
    "    - rmse_list, mae_list: performance metrics per iteration\n",
    "    - item_type_stats: per-round asked item type counts\n",
    "    \"\"\"\n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    rmse_list, mae_list = [], []\n",
    "    asked_pairs = {u: set() for u in range(num_users)}  \n",
    "    item_type_stats = defaultdict(lambda: defaultdict(int))\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "\n",
    "    # Step 0: Baseline evaluation\n",
    "    print(\"üîç Evaluating baseline RMSE/MAE...\")\n",
    "    train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    trainset = data_r.build_full_trainset()\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "    test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "    test_data = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    testset = test_data.build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"‚úÖ Baseline evaluation complete.\")\n",
    "\n",
    "    # Iterative elicitation\n",
    "    for i in range(iteration):\n",
    "        print(f\"\\nüîÅ Iteration {i+1}/{iteration} (skip asked pairs, walk from root)\")\n",
    "        # Step 1: Retrain tree\n",
    "        warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "        coldK_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "        x_df = pd.concat([warm_df, coldK_df], ignore_index=False)\n",
    "\n",
    "        pct = Tree(max_depth=i+1, min_instances=5, item_type_map=item_type_map)\n",
    "        pct.fit(x_df, x_df, strategy=strategy)\n",
    "        print(\"üå≥ Tree re-trained.\")\n",
    "\n",
    "        for u in range(num_users):\n",
    "            node = pct.root\n",
    "            while node and not node.is_leaf and node.attribute_name:\n",
    "                itemA, itemB = node.attribute_name\n",
    "                if itemA not in cid_to_idx or itemB not in cid_to_idx:\n",
    "                    node = None\n",
    "                    break\n",
    "\n",
    "                itemA_idx = cid_to_idx[itemA]\n",
    "                itemB_idx = cid_to_idx[itemB]\n",
    "                pair = frozenset([itemA_idx, itemB_idx])\n",
    "  \n",
    "                if pair in asked_pairs[u]:\n",
    "                    ratingA = train_copy[u, itemA_idx]\n",
    "                    ratingB = train_copy[u, itemB_idx]\n",
    "                    if ratingA > ratingB:\n",
    "                        node = node.children[0]\n",
    "                    elif ratingB > ratingA:\n",
    "                        node = node.children[1]\n",
    "                    else:\n",
    "                        node = node.children[2]\n",
    "                    continue\n",
    "\n",
    "                # First unasked pair found\n",
    "                ratingA = X_copy[u, itemA_idx]\n",
    "                ratingB = X_copy[u, itemB_idx]\n",
    "\n",
    "                if ratingA > 0:\n",
    "                    train_copy[u, itemA_idx] = ratingA\n",
    "                    X_copy[u, itemA_idx] = 0\n",
    "                if ratingB > 0:\n",
    "                    train_copy[u, itemB_idx] = ratingB\n",
    "                    X_copy[u, itemB_idx] = 0\n",
    "\n",
    "                asked_pairs[u].add(pair)  \n",
    "\n",
    "                # üåü Record item type (based on itemA)\n",
    "                item_type = get_item_type(itemA)\n",
    "                item_type_stats[i][item_type] += 1\n",
    "\n",
    "                break  # only one pair per user per iteration\n",
    "\n",
    "        # Step 2: Evaluate\n",
    "        print(\"üìä Evaluating after this iteration...\")\n",
    "        train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "        data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        trainset = data_r.build_full_trainset()\n",
    "        algo.fit(trainset)\n",
    "        test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "        test_data = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        testset = test_data.build_full_trainset().build_testset()\n",
    "        predictions = algo.test(testset)\n",
    "        rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "        mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "        print(f\"‚úÖ Iteration {i+1} complete.\")\n",
    "\n",
    "    return rmse_list, mae_list, item_type_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f2fb4-0155-4ecf-a714-8eadd82ee60d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore runtime warnings\n",
    "\n",
    "pairwise_tree_1 = elicitation_by_pairwise_tree_retrain_skiped(\n",
    "    Tree=Tree,\n",
    "    train=train_cold_K_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    iteration=20, strategy=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519f5aa-3e62-464b-a8dc-1745147470f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list, mae_list, item_type_stats = pairwise_tree_1 \n",
    "for round_i, type_counts in item_type_stats.items():\n",
    "    total = sum(type_counts.values())\n",
    "    ratios = {k: v / total for k, v in type_counts.items()}\n",
    "    print(f\"Round {round_i+1}: {ratios}\")\n",
    "item_type_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d10cb6-7559-4786-84f1-0499c1676858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore runtime warnings\n",
    "\n",
    "pairwise_tree_2 = elicitation_by_pairwise_tree_retrain_skiped(\n",
    "    Tree=Tree,\n",
    "    train=train_cold_K_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    iteration=20, strategy=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483f20d-d1e5-430a-b0ea-ceedfd2dc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list, mae_list, item_type_stats = pairwise_tree_2 \n",
    "for round_i, type_counts in item_type_stats.items():\n",
    "    total = sum(type_counts.values())\n",
    "    ratios = {k: v / total for k, v in type_counts.items()}\n",
    "    print(f\"Round {round_i+1}: {ratios}\")\n",
    "item_type_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ce813-6650-4279-9006-8f92c5734dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore runtime warnings\n",
    "\n",
    "pairwise_tree_3 = elicitation_by_pairwise_tree_retrain_skiped(\n",
    "    Tree=Tree,\n",
    "    train=train_cold_K_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    iteration=20, strategy=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9a960-1540-4c16-9d4a-630b4a6b3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list, mae_list, item_type_stats = pairwise_tree_3 \n",
    "for round_i, type_counts in item_type_stats.items():\n",
    "    total = sum(type_counts.values())\n",
    "    ratios = {k: v / total for k, v in type_counts.items()}\n",
    "    print(f\"Round {round_i+1}: {ratios}\")\n",
    "item_type_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aab10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
