{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "42c86d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"..\"))  \n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064955c7-6535-4302-a999-57c927b4874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pysparnn.cluster_index as ci\n",
    "# import scipy.sparse\n",
    "# import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.sparse as sp\n",
    "from utils import train_test_split, df_to_matrix ,matrix_to_df_2, threshold_interactions_df, matrix_to_df,set_intersection,get_0_and_p_index,set_diff, matrix_to_full_df, threshold_interactions_df_plus, train_test_split_csr\n",
    "\n",
    "# !pip install surprise\n",
    "from surprise import Reader, accuracy\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pct.tree.heuristic.Heuristic import Heuristic5\n",
    "from pct.tree.heuristic.semibi_NumericHeuristic import NumericHeuristic5 \n",
    "from pct.tree.splitter.semibi_splitter import Splitter \n",
    "from pct.tree.semibi_tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ec74b799-9042-4572-872f-587da73263e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>item_type</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>genre_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>238709</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>238709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>169510</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>169510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>208084</td>\n",
       "      <td>1.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>208084</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>245398</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>245398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>153166</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>153166</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524889</th>\n",
       "      <td>248947</td>\n",
       "      <td>83754</td>\n",
       "      <td>0.01</td>\n",
       "      <td>artist</td>\n",
       "      <td>83754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524890</th>\n",
       "      <td>248947</td>\n",
       "      <td>141799</td>\n",
       "      <td>0.00</td>\n",
       "      <td>genre</td>\n",
       "      <td>0</td>\n",
       "      <td>[141799]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524891</th>\n",
       "      <td>248947</td>\n",
       "      <td>141677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>141677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524892</th>\n",
       "      <td>248947</td>\n",
       "      <td>262458</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>262458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524893</th>\n",
       "      <td>248947</td>\n",
       "      <td>146871</td>\n",
       "      <td>0.00</td>\n",
       "      <td>artist</td>\n",
       "      <td>146871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1524894 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  rating item_type  artist_id genre_ids\n",
       "0              9   238709    0.00    artist     238709         0\n",
       "1              9   169510    0.00    artist     169510         0\n",
       "2              9   208084    1.00    artist     208084         0\n",
       "3              9   245398    0.00    artist     245398         0\n",
       "4              9   153166    0.00    artist     153166         0\n",
       "...          ...      ...     ...       ...        ...       ...\n",
       "1524889   248947    83754    0.01    artist      83754         0\n",
       "1524890   248947   141799    0.00     genre          0  [141799]\n",
       "1524891   248947   141677    0.00    artist     141677         0\n",
       "1524892   248947   262458    0.00    artist     262458         0\n",
       "1524893   248947   146871    0.00    artist     146871         0\n",
       "\n",
       "[1524894 rows x 6 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = pd.read_csv(\"filtered_semi_binary.csv\")\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24cccb84-a9fa-4029-a5fd-a4abb6752eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item type map\n",
    "item_type_map = filtered_df.drop_duplicates(subset='item_id')[['item_id', 'item_type']]\n",
    "item_type_map = dict(zip(item_type_map['item_id'], item_type_map['item_type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9faf9fac-677d-44ae-82f5-9144bdcf2674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_type(item_id):\n",
    "    return item_type_map.get(item_id, 'unknown')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "286d735d-1037-4e02-889c-fbd9a9c23bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist\n"
     ]
    }
   ],
   "source": [
    "print(get_item_type(172223))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "24c1e96b-cf4a-4df9-8ea1-8c09a6740405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist\n",
      "genre\n"
     ]
    }
   ],
   "source": [
    "print(get_item_type(238709))  \n",
    "print(get_item_type(141799))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "574e2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_user_ids = sorted(filtered_df['user_id'].unique().tolist())\n",
    "\n",
    "def split_users_by_ratio(all_user_ids, ratio):\n",
    "    n = len(all_user_ids)\n",
    "    split_point = int(n * ratio)\n",
    "    warm_users = all_user_ids[:split_point]\n",
    "    cold_users = all_user_ids[split_point:]\n",
    "    return warm_users, cold_users\n",
    "\n",
    "# Example ratios from 10% to 50%\n",
    "# ratios = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# splits = {r: split_users_by_ratio(all_user_ids, r) for r in ratios}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4056d4",
   "metadata": {},
   "source": [
    "## 10% warm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cfd5f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_users_idx, cold_users_idx = split_users_by_ratio(all_user_ids, 0.1)\n",
    "\n",
    "df_warm = filtered_df[filtered_df['user_id'].isin(warm_users_idx)].copy()\n",
    "df_cold = filtered_df[filtered_df['user_id'].isin(cold_users_idx)].copy()\n",
    "\n",
    "matrix_warm, rid_to_idx_warm, idx_to_rid_warm, cid_to_idx, idx_to_cid = df_to_matrix(\n",
    "    df_warm, \"user_id\", \"item_id\", \"rating\")\n",
    "\n",
    "\n",
    "matrix_cold, rid_to_idx_cold, idx_to_rid_cold, _, _ = df_to_matrix( \n",
    "    df_cold, \"user_id\", \"item_id\", \"rating\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5a9d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_combine(strategy=\"artist-only\"):\n",
    "    \"\"\"Handles both approaches with proper matrix alignment\"\"\"\n",
    "    # Get full cold matrix and mappings\n",
    "    matrix_cold, rid_to_idx_cold, _, cid_to_idx, _ = df_to_matrix(\n",
    "        df_cold, \"user_id\", \"item_id\", \"rating\"\n",
    "    )\n",
    "    matrix_cold = matrix_cold.tocsr()\n",
    "\n",
    "    # Create boolean masks\n",
    "    artist_mask = np.isin(\n",
    "        np.arange(matrix_cold.shape[1]), \n",
    "        [cid_to_idx[iid] for iid in df_cold[df_cold['item_type'] == 'artist']['item_id']]\n",
    "    )\n",
    "    genre_mask = ~artist_mask\n",
    "\n",
    "    # Create aligned matrices\n",
    "    matrix_cold_artist = matrix_cold.multiply(artist_mask)\n",
    "    matrix_cold_genre = matrix_cold.multiply(genre_mask)\n",
    "    matrix_cold_artist = matrix_cold.multiply(artist_mask).tocsr()\n",
    "    matrix_cold_genre = matrix_cold.multiply(genre_mask).tocsr()\n",
    "\n",
    "    al_artist, test_cold, _ = train_test_split(\n",
    "        matrix_cold_artist, \n",
    "        split_count=30,\n",
    "        fraction=None\n",
    "    )\n",
    "    \n",
    "    if strategy == \"artist-only\":\n",
    "        X_cold, K_cold, _ = train_test_split_csr(al_artist, 1)  \n",
    "        return K_cold, X_cold, test_cold\n",
    "    \n",
    "    elif strategy == \"hybrid\":\n",
    "        X_cold, K_cold, _ = train_test_split_csr(al_artist, 1)\n",
    "        X_cold = X_cold + matrix_cold_genre\n",
    "        return K_cold, X_cold, test_cold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96fa0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 7\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "train_cold_K_artist, X_cold_artist, test_cold_artist  = split_and_combine(\"artist-only\")\n",
    "train_cold_K_hybrid, X_cold_hybrid, test_cold_hybrid = split_and_combine(\"hybrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dbc19bf4-a23c-4b33-b45c-751ac90f83f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cold users in X: 1531\n",
      "Cold items in X: 5011\n",
      "test users in test: 1475\n",
      "test items in test: 3980\n",
      "train users in train: 689\n",
      "train items in train: 587\n",
      "-------------------\n",
      "Shape of test_cold: (1531, 5011)\n",
      "Shape of train_cold: (1531, 5011)\n",
      "Shape of X_cold: (1531, 5011)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cold users in X: {len(np.unique(X_cold_hybrid.nonzero()[0]))}\")\n",
    "print(f\"Cold items in X: {len(np.unique(X_cold_hybrid.nonzero()[1]))}\")\n",
    "print(f\"test users in test: {len(np.unique(test_cold_hybrid.nonzero()[0]))}\")\n",
    "print(f\"test items in test: {len(np.unique(test_cold_hybrid.nonzero()[1]))}\")\n",
    "print(f\"train users in train: {len(np.unique(train_cold_K_hybrid.nonzero()[0]))}\")\n",
    "print(f\"train items in train: {len(np.unique(train_cold_K_hybrid.nonzero()[1]))}\")\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "# shape of test_cold\n",
    "print(f\"Shape of test_cold: {test_cold_hybrid.shape}\")\n",
    "print(f\"Shape of train_cold: {train_cold_K_hybrid.shape}\")\n",
    "print(f\"Shape of X_cold: {X_cold_hybrid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f09c03-9cd8-4235-b86e-52375b580de4",
   "metadata": {},
   "source": [
    "# X with artist + genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6670eaf7-59c7-4067-baf0-741458394944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "import pandas as pd\n",
    "\n",
    "def elicitation_by_tree_path_retrain_skiped_warm_type(Tree, train, test, X, matrix_warm, idx_to_rid_cold, idx_to_rid_warm, idx_to_cid, iteration=5):\n",
    "    \"\"\"\n",
    "    Method 3 (revised): Retrain tree at each round. For each user, traverse from root down the tree.\n",
    "    At each level, if the item was already asked (stored in asked_items), go deeper.\n",
    "    Ask the first item the user hasn't been asked before.\n",
    "\n",
    "    Parameters:\n",
    "    - Tree: class of the decision tree model\n",
    "    - train, test, X: lil_matrix (known ratings, test set, and full matrix)\n",
    "    - matrix_warm: lil_matrix of warm user ratings\n",
    "    - idx_to_rid_*, idx_to_cid: mapping from indices to real user/item IDs\n",
    "    - iteration: number of elicitation rounds\n",
    "\n",
    "    Returns:\n",
    "    - rmse_list, mae_list: performance at each round\n",
    "    - item_type_stats: {round_i: {'artist': count, 'genre': count, ...}, ...}\n",
    "    \"\"\"\n",
    "\n",
    "    num_users, num_items = train.shape\n",
    "    train_copy = train.tolil().copy()\n",
    "    X_copy = X.tolil().copy()\n",
    "    rmse_list, mae_list = [], []\n",
    "    cid_to_idx = {v: k for k, v in idx_to_cid.items()}\n",
    "    asked_items = {u: set() for u in range(num_users)}  \n",
    "    item_type_stats = defaultdict(lambda: defaultdict(int))  # 🌟 item type statistics each iteration\n",
    "\n",
    "    # Step 0: Baseline evaluation\n",
    "    print(\"🔍 Evaluating baseline RMSE/MAE...\")\n",
    "    train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    trainset = data_r.build_full_trainset()\n",
    "    algo = SVD()\n",
    "    algo.fit(trainset)\n",
    "    test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "    test_data = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    testset = test_data.build_full_trainset().build_testset()\n",
    "    predictions = algo.test(testset)\n",
    "    rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "    mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "    print(\"✅ Baseline evaluation complete.\")\n",
    "\n",
    "    # Iterative elicitation\n",
    "    for i in range(iteration):\n",
    "        print(f\"\\n🔁 Iteration {i+1}/{iteration} (skip asked items, walk from root)\")\n",
    "        # Retrain tree using current train_copy\n",
    "        warm_df = matrix_to_full_df(matrix_warm, idx_to_rid_warm, idx_to_cid)\n",
    "        coldK_df = matrix_to_full_df(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "        x_df = pd.concat([warm_df, coldK_df], ignore_index=False)\n",
    "\n",
    "        pct = Tree(max_depth=i + 1, min_instances=5)\n",
    "        pct.fit(x_df, x_df)\n",
    "        print(\"🌳 Tree re-trained.\")\n",
    "\n",
    "        for u in range(num_users):\n",
    "            node = pct.root\n",
    "\n",
    "            # Traverse down the tree until we find an unasked item\n",
    "            while node and not node.is_leaf and node.attribute_name:\n",
    "                item = node.attribute_name\n",
    "                if item not in cid_to_idx:\n",
    "                    node = None\n",
    "                    break\n",
    "\n",
    "                item_idx = cid_to_idx[item]\n",
    "\n",
    "                if item_idx in asked_items[u]:\n",
    "                    # Already asked, go deeper based on user's rating\n",
    "                    rating = train_copy[u, item_idx]\n",
    "                    if rating > 0.01:\n",
    "                        node = node.children[0]\n",
    "                    elif rating > 0:\n",
    "                        node = node.children[1]\n",
    "                    else:\n",
    "                        node = node.children[2]\n",
    "                    continue\n",
    "\n",
    "                # First unasked item: try to add it to training\n",
    "                asked_items[u].add(item_idx)\n",
    "                rating = X_copy[u, item_idx]\n",
    "                if rating > 0:\n",
    "                    train_copy[u, item_idx] = rating\n",
    "                    X_copy[u, item_idx] = 0\n",
    "\n",
    "                # 🌟 record item type\n",
    "                item_type = get_item_type(item)  \n",
    "                item_type_stats[i][item_type] += 1\n",
    "\n",
    "                break  # only ask one item per user per iteration\n",
    "\n",
    "        # Step 3: Evaluate with SVD\n",
    "        print(\"📊 Evaluating after this iteration...\")\n",
    "        train_df = matrix_to_df_2(train_copy, idx_to_rid_cold, idx_to_cid)\n",
    "        data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        trainset = data_r.build_full_trainset()\n",
    "        algo.fit(trainset)\n",
    "        test_df = matrix_to_df_2(test, idx_to_rid_cold, idx_to_cid)\n",
    "        test_data = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        testset = test_data.build_full_trainset().build_testset()\n",
    "        predictions = algo.test(testset)\n",
    "        rmse_list.append(accuracy.rmse(predictions, verbose=True))\n",
    "        mae_list.append(accuracy.mae(predictions, verbose=True))\n",
    "        print(f\"✅ Iteration {i+1} complete.\")\n",
    "\n",
    "    return rmse_list, mae_list, item_type_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "719f2fb4-0155-4ecf-a714-8eadd82ee60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating baseline RMSE/MAE...\n",
      "RMSE: 0.5674\n",
      "MAE:  0.3739\n",
      "✅ Baseline evaluation complete.\n",
      "\n",
      "🔁 Iteration 1/4 (skip asked items, walk from root)\n",
      "Initializing Splitter...\n",
      "✅ Calling build()...\n",
      "✅ Tree built successfully!\n",
      "🌳 Tree re-trained.\n",
      "📊 Evaluating after this iteration...\n",
      "RMSE: 0.5660\n",
      "MAE:  0.3745\n",
      "✅ Iteration 1 complete.\n",
      "\n",
      "🔁 Iteration 2/4 (skip asked items, walk from root)\n",
      "Initializing Splitter...\n",
      "✅ Calling build()...\n",
      "✅ Tree built successfully!\n",
      "🌳 Tree re-trained.\n",
      "📊 Evaluating after this iteration...\n",
      "RMSE: 0.5528\n",
      "MAE:  0.3736\n",
      "✅ Iteration 2 complete.\n",
      "\n",
      "🔁 Iteration 3/4 (skip asked items, walk from root)\n",
      "Initializing Splitter...\n",
      "✅ Calling build()...\n",
      "✅ Tree built successfully!\n",
      "🌳 Tree re-trained.\n",
      "📊 Evaluating after this iteration...\n",
      "RMSE: 0.5499\n",
      "MAE:  0.3736\n",
      "✅ Iteration 3 complete.\n",
      "\n",
      "🔁 Iteration 4/4 (skip asked items, walk from root)\n",
      "Initializing Splitter...\n",
      "✅ Calling build()...\n",
      "✅ Tree built successfully!\n",
      "🌳 Tree re-trained.\n",
      "📊 Evaluating after this iteration...\n",
      "RMSE: 0.5486\n",
      "MAE:  0.3736\n",
      "✅ Iteration 4 complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore runtime warnings\n",
    "\n",
    "pct_hybrid_10_type = elicitation_by_tree_path_retrain_skiped_warm_type(\n",
    "    Tree=Tree,\n",
    "    train=train_cold_K_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    iteration=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efdfafe-16bd-4093-a523-4778e5b739a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# ignore runtime warnings\n",
    "\n",
    "pct_hybrid_10_type = elicitation_by_tree_path_retrain_skiped_warm_type(\n",
    "    Tree=Tree,\n",
    "    train=X_cold_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    matrix_warm=matrix_warm,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_rid_warm=idx_to_rid_warm,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    iteration=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9a960-1540-4c16-9d4a-630b4a6b3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list, mae_list, item_type_stats = pct_hybrid_10_type\n",
    "for round_i, type_counts in item_type_stats.items():\n",
    "    total = sum(type_counts.values())\n",
    "    ratios = {k: v / total for k, v in type_counts.items()}\n",
    "    print(f\"Round {round_i+1}: {ratios}\")\n",
    "item_type_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "44c03f15-632e-4dc2-9395-9132530c46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_baseline_from_elicitation_np_warm(matrix_warm, train, X, test):\n",
    "    \"\"\"\n",
    "    Train a single SVD model using full info: matrix_warm + train + X\n",
    "    Return RMSE and MAE on test set (Surprise-based).\n",
    "    \"\"\"\n",
    "    #  K + X\n",
    "    full_train_cold = train.copy().tolil()\n",
    "    X_copy = X.copy().tolil()\n",
    "    for u in range(train.shape[0]):\n",
    "        items = X_copy.getrow(u).nonzero()[1]\n",
    "        for item in items:\n",
    "            full_train_cold[u, item] = X[u, item]\n",
    "\n",
    "    # combine warm and  cold \n",
    "    full_matrix = sp.vstack([matrix_warm.tocsr(), full_train_cold.tocsr()])\n",
    "\n",
    "    #  convert dataframe\n",
    "    train_df = matrix_to_df_2(full_train_cold, idx_to_rid_cold, idx_to_cid)\n",
    "    test_df = matrix_to_df(test, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # train SVD \n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    data_rr = data_r.build_full_trainset()\n",
    "    algo = SVD()\n",
    "    algo.fit(data_rr)\n",
    "\n",
    "    # Predict on test\n",
    "    test_r = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    test_rr = test_r.build_full_trainset()\n",
    "    predictions = algo.test(test_rr.build_testset())\n",
    "    \n",
    "    rmse_val = accuracy.rmse(predictions)\n",
    "    mae_val = accuracy.mae(predictions)\n",
    "\n",
    "    print(f\"[Flat Baseline] RMSE = {rmse_val:.4f}, MAE = {mae_val:.4f}\")\n",
    "    return rmse_val, mae_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12a93e9c-1eb7-4200-94c7-34be817f4487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4078\n",
      "MAE:  0.3356\n",
      "[Flat Baseline] RMSE = 0.4078, MAE = 0.3356\n"
     ]
    }
   ],
   "source": [
    "flat_hybrid10 = flat_baseline_from_elicitation_np_warm(\n",
    "    matrix_warm=matrix_warm,\n",
    "    train=train_cold_K_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    test=test_cold_hybrid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "811bfba1-8b01-4bd8-ab3b-d2860df5296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_baseline_from_elicitation_np_coldonly(train, X, test):\n",
    "    \"\"\"\n",
    "    Train a single SVD model using full info from cold users only: train + X\n",
    "    Return RMSE and MAE on test set.\n",
    "    \"\"\"\n",
    "    # Merge train and X: cold users only\n",
    "    full_train_cold = train.copy().tolil()\n",
    "    X_copy = X.copy().tolil()\n",
    "    for u in range(train.shape[0]):\n",
    "        items = X_copy.getrow(u).nonzero()[1]\n",
    "        for item in items:\n",
    "            full_train_cold[u, item] = X[u, item]\n",
    "\n",
    "    # convert cold-only matrix to df\n",
    "    train_df = matrix_to_df_2(full_train_cold, idx_to_rid_cold, idx_to_cid)\n",
    "    test_df = matrix_to_df(test, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "    # train SVD on cold users\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    data_rr = data_r.build_full_trainset()\n",
    "    algo = SVD()\n",
    "    algo.fit(data_rr)\n",
    "\n",
    "    # Predict on test\n",
    "    test_r = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "    test_rr = test_r.build_full_trainset()\n",
    "    predictions = algo.test(test_rr.build_testset())\n",
    "    \n",
    "    rmse_val = accuracy.rmse(predictions)\n",
    "    mae_val = accuracy.mae(predictions)\n",
    "\n",
    "    print(f\"[Flat Baseline - Cold Only] RMSE = {rmse_val:.4f}, MAE = {mae_val:.4f}\")\n",
    "    return rmse_val, mae_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "14ad164a-2d95-4c85-ab9e-c3e0f9567d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4086\n",
      "MAE:  0.3361\n",
      "[Flat Baseline - Cold Only] RMSE = 0.4086, MAE = 0.3361\n"
     ]
    }
   ],
   "source": [
    "flat_hybrid10 = flat_baseline_from_elicitation_np_coldonly(\n",
    "    train=X_cold_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    test=test_cold_hybrid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f7832fdc-d9c8-4122-a9a8-dca60030097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "def select_top_n_per_user(X, n=10):\n",
    "    X = X.tocsr()\n",
    "    selected = sp.lil_matrix(X.shape)\n",
    "    for u in range(X.shape[0]):\n",
    "        row = X.getrow(u)\n",
    "        if row.nnz == 0:\n",
    "            continue\n",
    "        item_ids = row.indices\n",
    "        ratings = row.data\n",
    "        if np.allclose(ratings, ratings[0]):\n",
    "            # all scores are equal (e.g. semi-binary) => random top-n\n",
    "            selected_items = np.random.choice(item_ids, size=min(n, len(item_ids)), replace=False)\n",
    "        else:\n",
    "            top_n_idx = np.argsort(-ratings)[:n]\n",
    "            selected_items = item_ids[top_n_idx]\n",
    "        selected[u, selected_items] = X[u, selected_items]\n",
    "    return selected.tocsr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bd6bc1e4-f30c-4a30-bdac-042d5a04eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_topN_baselines(train_K, X, test, idx_to_rid_cold, idx_to_cid, N_list):\n",
    "    results = []\n",
    "\n",
    "    for N in N_list:\n",
    "        print(f\"\\n=== Running Top-{N} per user baseline ===\")\n",
    "\n",
    "        # Step 1: Top-N selection\n",
    "        X_selected = select_top_n_per_user(X, n=N)\n",
    "\n",
    "        # Step 2: Merge K + selected X via assignment (not addition!)\n",
    "        train_full = train_K.copy().tolil()\n",
    "        X_sel = X_selected.tolil()\n",
    "        for u in range(train_K.shape[0]):\n",
    "            items = X_sel.rows[u]\n",
    "            values = X_sel.data[u]\n",
    "            for item, value in zip(items, values):\n",
    "                train_full[u, item] = value\n",
    "        train_full = train_full.tocsr()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # Optional: check total number of ratings\n",
    "        total_ratings = train_full.count_nonzero()\n",
    "        print(f\"Total training ratings (K + top-{N} X): {total_ratings}\")\n",
    "\n",
    "        # Step 3: Convert to DataFrame\n",
    "        train_df = matrix_to_df(train_full, idx_to_rid_cold, idx_to_cid)\n",
    "        test_df = matrix_to_df(test, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "        # Step 4: Train SVD\n",
    "        reader = Reader(rating_scale=(0, 1))\n",
    "        data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        data_rr = data_r.build_full_trainset()\n",
    "\n",
    "        algo = SVD()\n",
    "        algo.fit(data_rr)\n",
    "\n",
    "        # Step 5: Predict\n",
    "        test_r = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        test_rr = test_r.build_full_trainset()\n",
    "        predictions = algo.test(test_rr.build_testset())\n",
    "\n",
    "        # Step 6: Evaluation\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "        mae = accuracy.mae(predictions)\n",
    "\n",
    "        results.append({\n",
    "            \"N_per_user\": N,\n",
    "            \"k+X_ratings\": total_ratings,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e07bdc3f-b4e6-4aee-9e29-adbc3350d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Top-25 per user baseline ===\n",
      "Total training ratings (K + top-25 X): 38776\n",
      "RMSE: 0.7000\n",
      "MAE:  0.5437\n",
      "\n",
      "=== Running Top-50 per user baseline ===\n",
      "Total training ratings (K + top-50 X): 75983\n",
      "RMSE: 0.6735\n",
      "MAE:  0.5180\n",
      "\n",
      "=== Running Top-100 per user baseline ===\n",
      "Total training ratings (K + top-100 X): 144932\n",
      "RMSE: 0.6142\n",
      "MAE:  0.4671\n",
      "\n",
      "=== Running Top-150 per user baseline ===\n",
      "Total training ratings (K + top-150 X): 206744\n",
      "RMSE: 0.5665\n",
      "MAE:  0.4269\n",
      "\n",
      "=== Running Top-200 per user baseline ===\n",
      "Total training ratings (K + top-200 X): 261628\n",
      "RMSE: 0.5320\n",
      "MAE:  0.4003\n",
      "\n",
      "=== Running Top-250 per user baseline ===\n",
      "Total training ratings (K + top-250 X): 309503\n",
      "RMSE: 0.5013\n",
      "MAE:  0.3808\n",
      "\n",
      "=== Running Top-300 per user baseline ===\n",
      "Total training ratings (K + top-300 X): 351627\n",
      "RMSE: 0.4765\n",
      "MAE:  0.3671\n",
      "\n",
      "=== Running Top-350 per user baseline ===\n",
      "Total training ratings (K + top-350 X): 388603\n",
      "RMSE: 0.4574\n",
      "MAE:  0.3577\n",
      "\n",
      "=== Running Top-400 per user baseline ===\n",
      "Total training ratings (K + top-400 X): 420424\n",
      "RMSE: 0.4428\n",
      "MAE:  0.3513\n",
      "\n",
      "=== Running Top-500 per user baseline ===\n",
      "Total training ratings (K + top-500 X): 468592\n",
      "RMSE: 0.4256\n",
      "MAE:  0.3449\n",
      "\n",
      "=== Running Top-550 per user baseline ===\n",
      "Total training ratings (K + top-550 X): 485697\n",
      "RMSE: 0.4207\n",
      "MAE:  0.3428\n",
      "\n",
      "📊 Baseline Performance Summary:\n",
      "    N_per_user  k+X_ratings      RMSE       MAE\n",
      "0           25        38776  0.700015  0.543661\n",
      "1           50        75983  0.673474  0.518040\n",
      "2          100       144932  0.614214  0.467084\n",
      "3          150       206744  0.566469  0.426875\n",
      "4          200       261628  0.532025  0.400261\n",
      "5          250       309503  0.501285  0.380830\n",
      "6          300       351627  0.476470  0.367126\n",
      "7          350       388603  0.457401  0.357734\n",
      "8          400       420424  0.442761  0.351344\n",
      "9          500       468592  0.425592  0.344877\n",
      "10         550       485697  0.420734  0.342849\n"
     ]
    }
   ],
   "source": [
    "N_values = [25, 50, 100, 150, 200, 250,300,350, 400, 500, 550]\n",
    "\n",
    "results_topN = run_topN_baselines(\n",
    "    train_K=train_cold_K_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    N_list=N_values\n",
    ")\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results_topN)\n",
    "print(\"\\n📊 Baseline Performance Summary:\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cc24a6c3-f5d1-4ccf-88c7-9272293e9caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_percent_per_user(X, percent=0.1, seed=42):\n",
    "    \"\"\"\n",
    "    For each user, randomly keep `percent` of their rated items in X.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X = X.tocsr()\n",
    "    selected = sp.lil_matrix(X.shape)\n",
    "    for u in range(X.shape[0]):\n",
    "        row = X.getrow(u)\n",
    "        item_ids = row.indices\n",
    "        ratings = row.data\n",
    "        n_keep = int(len(item_ids) * percent)\n",
    "        if n_keep == 0:\n",
    "            continue\n",
    "        selected_idx = np.random.choice(len(item_ids), size=n_keep, replace=False)\n",
    "        selected_items = item_ids[selected_idx]\n",
    "        selected[u, selected_items] = ratings[selected_idx]\n",
    "    return selected.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "023592dc-fefb-4a31-ab4b-2895d89c665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_percent_baselines(train_K, X, test, idx_to_rid_cold, idx_to_cid, percent_list):\n",
    "    results = []\n",
    "\n",
    "    for p in percent_list:\n",
    "        print(f\"\\n=== Running Random {int(p*100)}% per user baseline ===\")\n",
    "\n",
    "        # Step 1: 随机保留X评分\n",
    "        X_selected = select_random_percent_per_user(X, percent=p)\n",
    "\n",
    "        # Step 2: 合并 train_K 和 X_selected（逐项覆盖）\n",
    "        train_full = train_K.copy().tolil()\n",
    "        X_sel = X_selected.tolil()\n",
    "        for u in range(train_K.shape[0]):\n",
    "            items = X_sel.rows[u]\n",
    "            values = X_sel.data[u]\n",
    "            for item, value in zip(items, values):\n",
    "                train_full[u, item] = value\n",
    "        train_full = train_full.tocsr()\n",
    "\n",
    "        # Step 3: 转换 dataframe\n",
    "        train_df = matrix_to_df(train_full, idx_to_rid_cold, idx_to_cid)\n",
    "        test_df = matrix_to_df(test, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "        # Step 4: 训练 SVD\n",
    "        reader = Reader(rating_scale=(0, 1))\n",
    "        data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        data_rr = data_r.build_full_trainset()\n",
    "\n",
    "        algo = SVD()\n",
    "        algo.fit(data_rr)\n",
    "\n",
    "        # Step 5: 预测并评估\n",
    "        test_r = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        test_rr = test_r.build_full_trainset()\n",
    "        predictions = algo.test(test_rr.build_testset())\n",
    "\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "        mae = accuracy.mae(predictions)\n",
    "        total_ratings = train_full.count_nonzero()\n",
    "\n",
    "        results.append({\n",
    "            \"percent\": p,\n",
    "            \"k+X_ratings\": total_ratings,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "01700826-18b0-4c7e-ac26-ee8c91b2e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Random 10% per user baseline ===\n",
      "RMSE: 0.4278\n",
      "MAE:  0.3574\n",
      "\n",
      "=== Running Random 15% per user baseline ===\n",
      "RMSE: 0.4236\n",
      "MAE:  0.3521\n",
      "\n",
      "=== Running Random 20% per user baseline ===\n",
      "RMSE: 0.4216\n",
      "MAE:  0.3486\n",
      "\n",
      "=== Running Random 30% per user baseline ===\n",
      "RMSE: 0.4185\n",
      "MAE:  0.3451\n",
      "\n",
      "=== Running Random 50% per user baseline ===\n",
      "RMSE: 0.4143\n",
      "MAE:  0.3414\n",
      "\n",
      "=== Running Random 80% per user baseline ===\n",
      "RMSE: 0.4098\n",
      "MAE:  0.3381\n",
      "\n",
      "=== Running Random 90% per user baseline ===\n",
      "RMSE: 0.4087\n",
      "MAE:  0.3367\n",
      "\n",
      "=== Running Random 100% per user baseline ===\n",
      "RMSE: 0.4080\n",
      "MAE:  0.3357\n",
      "   percent  k+X_ratings      RMSE       MAE\n",
      "0     0.10        57831  0.427806  0.357392\n",
      "1     0.15        86737  0.423580  0.352123\n",
      "2     0.20       115768  0.421574  0.348557\n",
      "3     0.30       173540  0.418497  0.345112\n",
      "4     0.50       289530  0.414329  0.341424\n",
      "5     0.80       462820  0.409836  0.338109\n",
      "6     0.90       520591  0.408695  0.336673\n",
      "7     1.00       579131  0.407990  0.335724\n"
     ]
    }
   ],
   "source": [
    "percent_values = [ 0.10, 0.15, 0.20, 0.30, 0.50,0.80,0.90,1]\n",
    "\n",
    "results_random = run_random_percent_baselines(\n",
    "    train_K=train_cold_K_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    percent_list=percent_values\n",
    ")\n",
    "\n",
    "df_random = pd.DataFrame(results_random)\n",
    "print(df_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "08b7763e-5c24-4e92-a09c-654ade3b21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_n_per_user(X, n=10, seed=42):\n",
    "    \"\"\"\n",
    "    For each user, randomly select up to `n` rated items from X.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    X = X.tocsr()\n",
    "    selected = sp.lil_matrix(X.shape)\n",
    "    for u in range(X.shape[0]):\n",
    "        row = X.getrow(u)\n",
    "        item_ids = row.indices\n",
    "        ratings = row.data\n",
    "        if len(item_ids) == 0:\n",
    "            continue\n",
    "        n_keep = min(n, len(item_ids))\n",
    "        selected_idx = np.random.choice(len(item_ids), size=n_keep, replace=False)\n",
    "        selected_items = item_ids[selected_idx]\n",
    "        selected[u, selected_items] = ratings[selected_idx]\n",
    "    return selected.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5dd5cdee-c9e1-404b-b8af-011ef1a002e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_n_baselines(train_K, X, test, idx_to_rid_cold, idx_to_cid, N_list):\n",
    "    results = []\n",
    "\n",
    "    for N in N_list:\n",
    "        print(f\"\\n=== Running Random-N={N} per user baseline ===\")\n",
    "\n",
    "        # Step 1: 随机选择每个用户的N个评分项\n",
    "        X_selected = select_random_n_per_user(X, n=N)\n",
    "\n",
    "        # Step 2: 合并 train_K 和 X_selected（逐项覆盖）\n",
    "        train_full = train_K.copy().tolil()\n",
    "        X_sel = X_selected.tolil()\n",
    "        for u in range(train_K.shape[0]):\n",
    "            items = X_sel.rows[u]\n",
    "            values = X_sel.data[u]\n",
    "            for item, value in zip(items, values):\n",
    "                train_full[u, item] = value\n",
    "        train_full = train_full.tocsr()\n",
    "\n",
    "        # Step 3: 转换为 dataframe\n",
    "        train_df = matrix_to_df(train_full, idx_to_rid_cold, idx_to_cid)\n",
    "        test_df = matrix_to_df(test, idx_to_rid_cold, idx_to_cid)\n",
    "\n",
    "        # Step 4: SVD 训练\n",
    "        reader = Reader(rating_scale=(0, 1))\n",
    "        data_r = Dataset.load_from_df(train_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        data_rr = data_r.build_full_trainset()\n",
    "\n",
    "        algo = SVD()\n",
    "        algo.fit(data_rr)\n",
    "\n",
    "        # Step 5: 预测并评估\n",
    "        test_r = Dataset.load_from_df(test_df[['user_id', 'item_id', 'rating']], reader)\n",
    "        test_rr = test_r.build_full_trainset()\n",
    "        predictions = algo.test(test_rr.build_testset())\n",
    "\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "        mae = accuracy.mae(predictions)\n",
    "        total_ratings = train_full.count_nonzero()\n",
    "\n",
    "        results.append({\n",
    "            \"N_per_user\": N,\n",
    "            \"k+X_ratings\": total_ratings,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "42dd422d-0bbc-4420-a833-3f3a7d00f995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Random-N=5 per user baseline ===\n",
      "RMSE: 0.4607\n",
      "MAE:  0.4306\n",
      "\n",
      "=== Running Random-N=10 per user baseline ===\n",
      "RMSE: 0.4462\n",
      "MAE:  0.4020\n",
      "\n",
      "=== Running Random-N=25 per user baseline ===\n",
      "RMSE: 0.4321\n",
      "MAE:  0.3662\n",
      "\n",
      "=== Running Random-N=50 per user baseline ===\n",
      "RMSE: 0.4245\n",
      "MAE:  0.3526\n",
      "\n",
      "=== Running Random-N=100 per user baseline ===\n",
      "RMSE: 0.4199\n",
      "MAE:  0.3466\n",
      "\n",
      "📊 Random-N Baseline Summary:\n",
      "   N_per_user  k+X_ratings      RMSE       MAE\n",
      "0           5         8340  0.460717  0.430572\n",
      "1          10        15976  0.446208  0.402029\n",
      "2          25        38776  0.432144  0.366222\n",
      "3          50        75983  0.424501  0.352581\n",
      "4         100       144932  0.419924  0.346605\n"
     ]
    }
   ],
   "source": [
    "N_values = [5, 10, 25, 50, 100]\n",
    "\n",
    "results_randomN = run_random_n_baselines(\n",
    "    train_K=train_cold_K_hybrid,\n",
    "    X=X_cold_hybrid,\n",
    "    test=test_cold_hybrid,\n",
    "    idx_to_rid_cold=idx_to_rid_cold,\n",
    "    idx_to_cid=idx_to_cid,\n",
    "    N_list=N_values\n",
    ")\n",
    "\n",
    "df_randomN = pd.DataFrame(results_randomN)\n",
    "print(\"\\n📊 Random-N Baseline Summary:\")\n",
    "print(df_randomN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37d2e9-3279-4e2b-bb22-31dfe45041cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
